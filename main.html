<!DOCTYPE html>
<html lang="en">
	<head>
        <script src="https://threejs.org/build/three.js"></script>
		<script src="https://threejs.org/examples/js/controls/OrbitControls.js"></script>
    </head>
    <body>
        <div id="overlay">
            <div>
                <button id="startButton">Click to Play</button>
                <p>Audio playback requires user interaction.</p>
            </div>
        </div>
		<div id="container"></div>

        <!-- NEW  -->

		<!-- Shaders -->
		<script type="x-shader/x-vertex" id="vertexShader">

			precision highp float;
			attribute vec3 position;
			attribute vec2 uv;
			attribute vec3 normal; // new
			attribute float vertexDisplacement;	// new

			uniform mat4 projectionMatrix;
			uniform mat4 modelViewMatrix;	// this is modelMatrix (model) * viewMatrix (camera)
			uniform mat3 normalMatrix; // the inverse of the modelViewMatrix.
			uniform sampler2D tAudioData;

			varying vec2 vUV;
			varying vec3 vNormal;	// new

			void main() {
				vUV = uv;
				vNormal = normalize(normalMatrix * normal);

				vec3 p = position;
				float f = texture2D(tAudioData, vec2(p.x, 0.0)).r;		// get amplitude at this position - 0-255
				float displacement = 5.0;
				float i = step(vUV.y, f);
				// p.x += i;
				// p.y += i * displacement;
				// p.y += (f);
				// p.y += cos(i);

				gl_Position = projectionMatrix *
							  modelViewMatrix *
							  vec4(p,1.0);

			}

			// gl_Position = vec4( position, 1.0 );	// for the 2d interpretation on the plane
		</script>



		<script id="fragmentShader" type="x-shader/x-fragment">
			precision highp float;

			varying vec2 vUV;
			varying vec3 vNormal;	// new

			// uniform sampler2D brick;
			uniform vec3 colorData;
			uniform sampler2D tAudioData;

			void main() {
				// vec3 a_normal = normalize(v_normal);
				// vec3 brickColor = texture2D(brick,vUV).rgb ;
				// vec3 brickColor = texture2D(brick, normalize(vNormal)).rgb;

				/*
				* Explaination:
				* The tAudioData is passed in as an single array of values.
				* This means we cannot get it's x and y position, so we create a vec2 that is the x position with a 0 for y
				* Usually the value that is returned from a texture is a rgb vector, but each element only holds a single value
				* To only get this value we will call '.r' on the returned value instead of the usually '.rgb'.
				*
				* The step function returns 0.0 if y < x, otherwise it returns 0.0.

				*/

				vec3 backgroundColor = vec3( 0.125, 0.125, 0.125 );
				vec3 color = colorData;// * vNormal;
													//	data         x position and 0

				float f = texture2D( tAudioData, vec2( vUV.x, 0.0 ) ).r;		// gets uniform (array) and position on x
				float i = step(vUV.y, f);// * step(f-0.125, vUV.y);				// this fills in values for the y positions

				gl_FragColor = vec4(mix(backgroundColor,color,i), 1.0);// returns x(1-z) + y(z), so x, if z = 0, y

			}

		</script>

        <!-- END NEW -->

        <script type="module">
            var camera, scene, renderer, light, light2, light3, mesh;							// basic rendering
			var analyser, frequencyData;										// audio
			var uniforms;														// shader
			var cameraControls;													// movement
			var kolor;

            let WIDTH, HEIGHT;

            var startButton = document.getElementById('startButton');			// begin screen
            startButton.addEventListener('click',init);

            function init() {
                // set width and height
                WIDTH = window.innerWidth;
                HEIGHT = window.innerHeight;

				// remove overlay that presented the button
                var overlay = document.getElementById( 'overlay' );
                overlay.remove();

				// initialize scene and renderer
				initRenderer();													// placed first because camera needed renderer
                initScene();

				// handle resizing
                onWindowResize();
                window.addEventListener( 'resize', onWindowResize, false);

                animate();             											// get requestAnimationFrame and render
            }

            function initScene() {
                // create scene
                scene = new THREE.Scene();
				scene.background = new THREE.Color (0x000000);
				kolor = new THREE.Color(0x000000);

                // create camera
				initCamera();

                // add audio listener
                var fftSize = 128;	// this is double what actual gets captured in frequency count
                var listener = new THREE.AudioListener();
                var audio = new THREE.Audio( listener );
                var mediaElement = new Audio( './sounds/do-i-wanna-know.mp3' );
                mediaElement.loop = true;
                mediaElement.play();
                audio.setMediaElementSource( mediaElement );
                analyser = new THREE.AudioAnalyser(audio, fftSize);
				frequencyData = new Uint8Array(analyser.frequencyBinCount);
				frequencyData = analyser.data;
				fftSize = analyser.data.length;
				// console.log("frquencyData: "+analyser.data);
				// console.log("frequencyData/2: "+analyser.data.slice(0,analyser.data.length/2));

                // create sphere
				var radius = 3, segments = 20, rings = 20;
                var geometry = new THREE.SphereBufferGeometry(radius, segments, rings);
				// var geometry = new THREE.PlaneBufferGeometry(5,5,4);
                // Make material based on custom shader. Audio data is passed in through uniforms.
                // var material = new THREE.MeshPhongMaterial( { color: 0xffaa00, flatShading: true, shininess: 0 } );
                uniforms = {
                    tAudioData: {
                        value: new THREE.DataTexture(frequencyData, fftSize/2, 1, THREE.LuminanceFormat)
                    },
					colorData: {
						type: "c",
						value: kolor
					}
                };
                var material = new THREE.RawShaderMaterial({
                    uniforms: uniforms,
                    vertexShader: document.getElementById('vertexShader').textContent,
                    fragmentShader: document.getElementById('fragmentShader').textContent
                });
                mesh = new THREE.Mesh(geometry, material);
                mesh.position.set(0,0,0);
                scene.add(mesh);

            }

			function initCamera() {
				var fov = 50, aspect = WIDTH/HEIGHT, near = 1, far = 1000;

				// basic
				// camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
				// camera.position.set(15, 0, 0);
				// camera.lookAt(0,0,0);

				// movement
				camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
				camera.position.set(0, 3.5, 10);
				camera.lookAt(scene.position);
				cameraControls = new THREE.OrbitControls (
					camera, renderer.domElement
				);
				cameraControls.addEventListener("change",
					function(){
						camera.updateProjectionMatrix();
						render();
					}
				);
			}

            function initRenderer() {
                var container = document.getElementById('container');
                renderer = new THREE.WebGLRenderer({antialias: true});
                renderer.setSize(WIDTH, HEIGHT);
                renderer.setClearColor(0x888888, 1);
                container.appendChild(renderer.domElement);
            }


            function render(){
                // update frequency data every render
                analyser.getFrequencyData();
				frequencyData = analyser.data;
				scaley(frequencyData);				// make pulsate
				calculateRGB(frequencyData);
                uniforms.tAudioData.value.needsUpdate = true;

				// uniforms.tAudioData.value = analyser.data;
				uniforms.colorData.value = kolor;

				console.log(analyser.data);

                // render scene
                renderer.render(scene, camera);
            }

            // NEW
            function animate() {
                requestAnimationFrame(animate);
                render();
            }

            function onWindowResize() {
				WIDTH = window.innerWidth;
				HEIGHT = window.innerHeight;
                camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();
				renderer.setSize( window.innerWidth, window.innerHeight );
            }

			// changes the object's size based on music avg amplitude
			function scaley(freq) {
				// const avg = frequencyData => frequencyData.reduce((a,b) => a + b, 0);
				const avg = freq.reduce((a,b)=>a+b, 0)/freq.length;
				// we are going to use this to determine scale. scale will be from 0.75 to 1.25 depending on the 255 value.
				const newScale = (((avg/255.0)*100.0)/100.0)+0.50;	// we want to get this out of a value of 50
				mesh.scale.x = newScale;
				mesh.scale.y = newScale;
				mesh.scale.z = newScale;

				console.log("newScale: " + newScale);
			}

			function calculateRGB(freq) {
				const len = (freq.length - 16)/3; // there are 16 useless spots for some reason.
				var r = freq.slice(0,len-1).reduce((a,b)=>a+b, 0)/len;			// this will be 0-255 avg /255.0

				var g = freq.slice(len, (len*2)-1).reduce((a,b)=>a+b, 0)/len;

				var b = freq.slice((len*2)-1).reduce((a,b)=>a+b, 0)/len;

				kolor = new THREE.Color(r/255.0, g/255.0, b/255.0);
				console.log("r: "+kolor.r+", g: "+kolor.g+", b: "+kolor.b);

			}



        </script>
    </body>
</html>
